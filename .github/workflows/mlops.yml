name: MLOps Pipeline

permissions:
  contents: read
  packages: write

on:
  push:
    branches: [main]
  workflow_dispatch:
  schedule:
    - cron: '0 0 1 * *'  # monatlich am 1. um 00:00 UTC

jobs:
  drift:
    runs-on: ubuntu-latest
    outputs:
      drift: ${{ steps.detect.outputs.drift }}
    steps:
      - uses: actions/checkout@v3

      # 0) Versuch, das letzte latest_data.csv als Artifact herunterzuladen
      - name: Download latest_data artifact
        uses: actions/download-artifact@v4
        with:
          name: latest-data
          path: data
        continue-on-error: true   # beim ersten Lauf existiert das Artifact noch nicht

      - name: Install drift dependencies
        run: pip install pandas scipy joblib

      - name: Run drift detection
        id: detect
        env:
          OLD_DATA_PATH: data/reference_data.csv
          NEW_DATA_PATH: data/latest_data.csv
        run: |
          python drift_detector.py
          DRIFT=$(jq .drift_detected drift_result.json)
          echo "drift=$DRIFT" >> $GITHUB_OUTPUT

      - name: Upload drift result
        uses: actions/upload-artifact@v4
        with:
          name: drift-result
          path: drift_result.json

  retrain:
    needs: drift
    if: github.event_name == 'push' || needs.drift.outputs.drift == 'true' || github.event_name == 'schedule'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install retrain dependencies
        run: pip install -r requirements.txt mlflow

      - name: Retrain model on latest data
        env:
          TRAIN_DATA_PATH: data/latest_data.csv
        run: python retrain_model.py

      - name: Upload new model artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-artifact
          path: models/rf_model.pkl

  build-and-push:
    needs: retrain
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set lowercase owner name
        shell: bash
        env:
          OWNER: ${{ github.repository_owner }}
        run: |
          echo "OWNER_LC=${OWNER,,}" >> $GITHUB_ENV

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ghcr.io/${{ env.OWNER_LC }}/fraud-api:latest
            ghcr.io/${{ env.OWNER_LC }}/fraud-api:${{ github.sha }}

  deploy:
    needs: build-and-push
    permissions:
      contents: write    # brauchen wir, damit wir committen d√ºrfen
    runs-on: [self-hosted, Windows]
    env:
      API_TOKEN: ${{ secrets.API_TOKEN }}
      FRAUD_THRESHOLD: "0.4"
      MODEL_PATH: "models/rf_model.pkl"
    steps:
      - uses: actions/checkout@v3
        with:
          persist-credentials: true

      - name: Pull & restart container locally
        shell: cmd
        run: |
          docker pull ghcr.io/andipfluegl/fraud-api:latest
          docker rm -f fraud_api || echo No existing container
          docker run -d --name fraud_api ^
            --env "API_TOKEN=%API_TOKEN%" ^
            --env "FRAUD_THRESHOLD=%FRAUD_THRESHOLD%" ^
            --env "MODEL_PATH=%MODEL_PATH%" ^
            -p 5000:5000 ^
            -v "%GITHUB_WORKSPACE%\\data:/app/data" ^
            ghcr.io/andipfluegl/fraud-api:latest

      # 1) Stelle sicher, dass data-Ordner im Repo existiert
      - name: Ensure data directory
        shell: pwsh
        run: |
          New-Item -ItemType Directory -Path "$Env:GITHUB_WORKSPACE\data" -Force | Out-Null

      # 2) Kopiere latest_data.csv aus dem Container ins Repo
      - name: Extract latest_data.csv from container
        shell: pwsh
        run: |
          docker cp fraud_api:/app/data/latest_data.csv "$Env:GITHUB_WORKSPACE\data\latest_data.csv"

      # 3) Upload latest_data.csv als GitHub-Artifact
      - name: Upload latest_data.csv artifact
        uses: actions/upload-artifact@v4
        with:
          name: latest-data
          path: data/latest_data.csv
